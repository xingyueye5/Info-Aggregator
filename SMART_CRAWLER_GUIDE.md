# 智能爬虫与外部AI集成指南

## 概述

本次更新解决了系统在处理列表页、搜索页和聚合页时的核心问题，实现了智能页面识别、多层级内容抓取和外部AI API集成。

## 核心改进

### 1. 智能页面类型识别

系统现在能够自动判断网页类型：

- **文章详情页（article）**：包含完整文章内容的单篇页面
- **列表聚合页（list）**：包含多个文章链接的索引页面
- **未知类型（unknown）**：无法明确分类的页面

#### 识别算法

基于多维度启发式规则：

1. **列表页特征**
   - 检测搜索结果标识（"search", "results", "query"）
   - 检测分页标识（"page", "next", "prev"）
   - 检测卡片布局（`.card`, `.item`, `.entry` 等）
   - 高链接密度，低文本密度
   - 大量列表项（`<li>`）

2. **文章页特征**
   - 存在 `<article>` 标签
   - 主要内容区域（`<main>`, `.content`）
   - 丰富的段落内容（多个 `<p>` 标签）
   - 作者和发布日期信息
   - 高文本密度

### 2. 子链接智能提取

当识别为列表页时，系统会：

1. **提取有价值链接**
   - 使用多种选择器（`article a`, `.post a`, `h2 a` 等）
   - 转换为绝对URL
   - 限制数量（默认最多10条）

2. **过滤无效链接**
   - 排除登录/注册链接
   - 排除搜索/筛选/分类链接
   - 排除关于/联系/隐私政策等页面
   - 排除评论/分享等功能链接
   - 排除非同域链接
   - 排除媒体文件（图片、PDF、音视频）

3. **去重处理**
   - 使用 Set 确保链接唯一性

### 3. 多篇内容独立处理

对于列表页中的每个子链接：

1. **独立抓取**：分别访问每个子页面
2. **内容提取**：提取标题、作者、正文、发布时间
3. **去重检查**：使用内容哈希避免重复收录
4. **AI分析**：如果启用，对每篇文章独立进行AI分析
5. **数据存储**：每篇文章作为独立记录保存

### 4. 外部AI API集成

#### 支持的功能

- 使用外部Gemini API生成高级总结
- 可选中文翻译
- 支持自定义API URL和密钥

#### 使用方法

1. **在文章详情页**：点击"外部AI总结"按钮
2. **配置API信息**：
   - API URL：`https://pmpjfbhq.cn-nb1.rainapp.top/v1`
   - API Key：`sk-qNbdjNke4CdwOBIqJj4O4RoAdoItV2OJGii8lLA6j6B8lDT1`
   - 翻译选项：开启/关闭中文翻译
3. **生成总结**：点击"生成总结"按钮
4. **查看结果**：总结会显示在文章详情页的独立卡片中

## 数据库变更

### articles 表新增字段

- `parentArticleId`：父文章ID，用于关联从列表页抓取的子文章
- `pageType`：页面类型（article/list/unknown）

## API 变更

### 新增 API

#### `articles.generateExternalSummary`

使用外部AI生成文章总结

**输入参数：**
```typescript
{
  id: number;              // 文章ID
  apiUrl: string;          // 外部API URL
  apiKey: string;          // API密钥
  translateToChinese: boolean; // 是否翻译为中文
}
```

**返回值：**
```typescript
{
  summary: string;           // 生成的总结
  translatedSummary?: string; // 翻译后的总结（如果启用）
}
```

### 修改的 API

#### `sources.crawl`

现在使用智能爬虫（`crawlSourceSmart`）替代传统爬虫，自动处理列表页和文章页。

## 使用示例

### 示例1：抓取arXiv搜索结果页

**输入URL：** `https://arxiv.org/search/?query=machine+learning`

**处理流程：**
1. 系统识别为列表页
2. 提取前10篇论文的abstract页面链接
3. 逐个访问并提取论文信息
4. 保存为10篇独立文章记录

### 示例2：抓取知乎话题页

**输入URL：** `https://www.zhihu.com/topic/19551137/hot`

**处理流程：**
1. 系统识别为列表页
2. 提取热门回答/文章链接
3. 逐个抓取完整内容
4. 保存为多篇独立记录

### 示例3：抓取单篇博客文章

**输入URL：** `https://example.com/blog/article-title`

**处理流程：**
1. 系统识别为文章页
2. 直接提取文章内容
3. 保存为单篇记录

## 性能与限制

### 性能优化

- 子页面抓取间隔：1秒（避免过快请求）
- 最大子页面数量：10篇
- 内容截取：最多5000字符用于AI分析

### 已知限制

1. **反爬虫限制**：部分网站可能返回403错误
2. **动态内容**：无法处理需要JavaScript渲染的内容
3. **登录墙**：无法访问需要登录的内容
4. **API限流**：外部AI API可能有调用频率限制

## 合规性说明

系统严格遵守以下原则：

- ✅ 仅抓取公开可访问的内容
- ✅ 不绕过登录或反爬虫机制
- ✅ 尊重 robots.txt 和版权
- ✅ 用户主动提供内容链接
- ✅ 合理的请求间隔，避免对目标网站造成负担

## 测试覆盖

新功能包含完整的单元测试：

- ✅ 文章页识别测试
- ✅ 列表页识别测试
- ✅ 子链接提取测试
- ✅ 链接过滤测试
- ✅ 去重机制测试

运行测试：
```bash
pnpm test smartCrawler
```

## 故障排查

### 问题1：抓取失败返回403

**原因：** 目标网站的反爬虫机制

**解决方案：**
- 尝试使用RSS源（如果有）
- 手动复制文章内容并粘贴
- 联系网站管理员获取API访问权限

### 问题2：列表页未识别

**原因：** 页面结构不符合常见模式

**解决方案：**
- 直接访问具体文章页面
- 提交反馈以改进识别算法

### 问题3：外部AI总结失败

**原因：** API配置错误或网络问题

**解决方案：**
- 检查API URL和密钥是否正确
- 确认网络连接正常
- 查看错误提示信息

## 未来改进方向

1. **增强识别算法**：使用机器学习提高页面类型识别准确率
2. **支持更多平台**：针对特定平台（如Medium、Substack）优化
3. **浏览器渲染**：支持JavaScript动态内容
4. **智能去重**：基于语义相似度的去重
5. **批量外部总结**：支持一键为多篇文章生成外部AI总结

---

**最后更新：** 2026-01-12
